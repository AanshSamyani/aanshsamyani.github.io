---
title: 'Blog 2 - Induction Heads'
date: 2024-12-02
permalink: /posts/2013/08/blog-post-2/
# tags:
#   - Induction Heads
---

## **Why this blog?**
This is a blog highlighting my understanding of ***Induction Heads/Induction Circuits*** in reference to ***In-Context Learning*** of Large Language Models. A large part of this blog post is inspired and taken up from the following sources:
- [Neel Nanda's glossary explaining Induction Heads](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=_Jzi6YHRHKP1JziwdE02qdYZ)
- [Callum McDougall's LessWrong post](https://www.perfectlynormal.co.uk/blog-induction-heads-illustrated)
- [A Mathematical Framework of Transformers](https://transformer-circuits.pub/2021/framework/index.html)

**Note:** This is my interpretation of what Induction Heads are and is not representative of how strongly/differently the authors might interpret it.

## **Introduction**
***Induction Heads*** allow transformers to perform ***In-Context Learning*** of a specific kind.
***In-Context Learning (ICL)*** refers to the ability of language models, particularly large ones, to learn and perform tasks based on input examples provided in the same prompt without requiring the relevant examples to be seen during training. 
Lets say the model is being trained for learning fruits and their colours, the following prompt will result in the model predicting Red, because Red appears after Apple in the context above, such kinds of In-Context Learning tasks that involve some sort of a pattern matching, Induction Heads play a very important role. Even if the model hasn't seen any of these words during training, it still has this unique ability to predict the answer correctly.
```python
"""
  Apple: Red
  Banana: Yellow
  Orange: Orange
  Grapes: Green
  Apple:  

"""
``` 
## **Transformer Framework: Summary**
- The central object in the transformer is the ***residual stream***.
- Different heads in each layer can be thought of as *operating independently* of each other, reading and writing into the residual stream.
- Heads can compose to form circuits. For instance, 
***K-composition*** is when the output of one head is used to generate the *key vector* in the attention calculations of a subsequent head.
- We can describe the weight matrices $W_Q$ , $W_K$ and $W_V$ as *reading from* (or *projecting from*) the residual stream, and $W_O$ as *writing to* (or *embedding into*) the residual stream.
- We can think of the combined operations $W_Q$ and $W_K$ in terms of a single, low-rank matrix $W_{QK}$ := $W_Q. {W_K}^T$ , called the ***QK circuit***. This matrix defines a *bilinear form* on the vectors in the residual stream: ${v_i}^T.W_{QK}.v_j$ is the attention paid by the i th token to the j th token. Conceptually, this matrix tells us which tokens information is moved to and from in the residual stream.
- We can think of the combined operations $W_V$ and $W_O$ in terms of a single matrix $W_{OV}$ := $W_V.W_O$ , called the OV circuit. This matrix defines a map from residual stream vectors to residual stream vectors: if {v_j} is the residual stream vector at the source token, then ${v_j}^T.W_{OV}$ is the vector that gets moved from token j to the destination token (if j is attended to). Conceptually, this matrix tells us what information is moved from a token, if that token is attended to.

## **Induction Circuits - Working**
- An ***Induction Circuit*** is a 2-head circuit that uses ***K-Composition*** to produce the induction behaviour. The first head is a `previous_token_head` and the second head is an `induction_head`. 
- Consider the sequence: $A_1B_1.....A_2B_2$, the tokens $A_1$ and $A_2$ refer to the same token A with their subscripts denoting their position in the context/prompt provided. Similarly, $B_1$ and $B_2$ refer to the same token B with their subscripts denoting their position in the context/prompt provided.
- The first head in our Induction Circuit which is a `previous_token_head`.
  - This head attends from position $B_1$ to that of position $A_1$. 
  - This happens via our previous token head's ***QK-Circuit***.
  - Here, our ***Query (Q)*** is the token at position $B_1$
  - Since it is our previous token head, the ***Key (K)*** that our ***Query (Q)  $(= B_1)$*** will attend to the most will be the token previous to the token at position $B_1$, which is the token at the position $A_1$.
  - The ***QK-Circuit*** just infers what are the respective positions of our ***Query (Q)*** and ***Key (K)*** tokens.
  - Once it is found out what positions to attend to, the ***OV-Circuit*** comes into play.
  - The ***Value (V)*** reads the information stored in the ***Key (K)*** token (i.e token at position $A_1$). The information in this case is that the token at position $A_1$ is simply token A.
  - The ***Output (O)*** writes this information to the residual stream of the **Query (Q)** token (i.e token at position $B_1$). In other words, the ***Output (O)*** writes to the $B_1$ residual stream the feature ***"the token before me is A"***.
- The second head in our ***Induction Circuit*** is the `induction_head`.
  - The induction head's ***Query (Q)*** identifies that our token is at position $A_2$. Basically, the ***Query (Q)*** for our inducion head is the token at position $A_2$. 
  - Since this is an induction head, the ***Key (K)*** that our ***Query (Q)*** will attend to the most is the token with the feature ***"the token before me is A"***.
  - Thus, our ***Key (K)*** is the token at position $B_1$, which the ***Query (Q)***, the token at position $A_2$ attends to the most. This is the induction head ***QK-Circuit***.
  - Once it is decided which position to attend to, the ***OV-Circuit*** of the induction head comes into play.
  - The ***Value (V)*** reads the information from the ***Key (K)*** token (i.e the token at position $B_1$). The information in this case is that the token at position $B_1$ is simply token B.
  - The ***Output (O)*** writes this information into the residual stream of the ***Query (Q)*** token (i.e the token at position $A_2$). In other words, the ***Output (O)*** writes to the $A_2$ residual stream the feature ***"predict that the next token is B"***.

  ## ***Conclusion/Summary***
  1) ***Induction Circuits*** comprise of 2 heads - a `previous_token_head` and an `induction_head` in different layers.

  2) The layers in which these heads are present need not be consecutive, for example the previous_token_head can be in some ***layer $n$*** and the induction head can be in some ***layer $n + i$***, where $i >= 1$. This is because the ***K-Composition*** occurs over the residual stream which is used as a ***shared bandwidth*** across the differnet layers of a transformer.

  3) Each attention head has 3 inputs - query, key and value. Each can read from different subspaces of the residual stream, and so can compose with different outputs of previous heads. 

  4) The ***Query (Q)*** determines where to move the information to, the ***Key (K)*** determines where to move it from/where to extract the information from, ***Value (V)*** determines what information to read from the ***Key (K)*** and move, the ***Output (O)*** just writes the information off to the ***Query (Q)*** token.

  5) In the ***QK-Circuit*** of the `previous_token_head`, the ***Query (Q)*** attends the most to the ***Key (K)*** that comes before/previous to it.

  6) Meanwhile in the ***QK-Circuit*** of the `induction_head`, the ***Query (Q)*** attends the most to the ***Key (K)*** that has the feature ***"the token before me is X"***. 

  7) In the ***OV-Circuit*** of the `previous_head_token`, the final information written off in the residual stream is ***"the token before some ***Query ($Q_1$)*** token is some ***Key ($K_1$)*** token"***.

  8) Meanwhile in the ***OV-Circuit*** of the `induction_head`, the final information written off in the residual stream is ***"the token predicted after some ***Query ($Q_2$)*** token is some ***Key ($K_2$)*** token"***
  

